# ğŸ§  CareBot Agent  
### Multi-Agent AI Assistant using AutoGen + Ollama + FastAPI

ğŸ”— **Repository:** https://github.com/Ujjwal0207/carebot-agent

CareBot Agent is a **production-style, multi-agent conversational AI system** built using **Microsoft AutoGen**, **FastAPI**, **WebSockets**, and **local LLMs via Ollama**.

This project demonstrates how real-world AI assistants are designed using **agent orchestration**, **intent routing**, **memory extraction**, and **safe LLM integration** â€” without relying on paid APIs.

---

## ğŸš€ What Is This Project?

CareBot is an **empathetic AI assistant** that can:

- Understand user intent (greeting, emotional support, planning, safety)
- Route messages intelligently
- Respond empathetically using a Care agent
- Generate structured guidance using planner logic
- Extract long-term memory automatically
- Run completely **locally** using Ollama
- Communicate in **real time** using WebSockets

This is **not a simple chatbot** â€” it is a **multi-agent AI system** designed with production constraints in mind.

---

## ğŸ—ï¸ High-Level Architecture

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Browser UI      â”‚
â”‚  (HTML + JavaScript) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚  WebSocket
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      FastAPI Server        â”‚
â”‚   web/server.py            â”‚
â”‚  â€¢ WebSocket handling      â”‚
â”‚  â€¢ Session management      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Agent Orchestrator     â”‚
â”‚        app/main.py         â”‚
â”‚  â€¢ run_agent()             â”‚
â”‚  â€¢ Conversation lifecycle â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Intent Router       â”‚
â”‚        app/router.py       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Safety   â”‚  Care     â”‚ â”‚
â”‚  â”‚ Handling â”‚  Mode     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚          Planner Mode      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RAG Context Builder      â”‚
â”‚        app/rag.py          â”‚
â”‚  â€¢ Memory retrieval        â”‚
â”‚  â€¢ Context injection      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      CareBot Agent         â”‚
â”‚  (AutoGen + Ollama LLM)    â”‚
â”‚  â€¢ Empathetic responses   â”‚
â”‚  â€¢ Structured reasoning   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Memory Extractor Agent    â”‚
â”‚  â€¢ JSON memory decisions  â”‚
â”‚  â€¢ Long-term storage      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Response to WebSocket    â”‚
â”‚        â†’ Browser UI        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜




## ğŸ¤– Agents in This System

### 1ï¸âƒ£ CareBot Agent
- Built with `ConversableAgent`
- Provides empathetic, human-like responses
- Uses system prompts to guide tone and behavior

### 2ï¸âƒ£ Memory Extractor Agent
- Automatically decides **what is worth remembering**
- Outputs structured JSON
- Stores long-term memory safely

> âš ï¸ AutoGen is used **correctly**:  
> `generate_reply()` is used for LLM calls (not agent-to-agent chat with Ollama).

---

## ğŸ”€ Intent Routing

Messages are routed before LLM invocation:

| Intent | Example |
|------|--------|
| `safety` | â€œI want to harm myselfâ€ |
| `care` | â€œI feel lost and overwhelmedâ€ |
| `planner` | â€œWhat should I do next?â€ |
| `greeting` | â€œHiâ€, â€œHelloâ€ |

This keeps responses safe, relevant, and predictable.

---

## ğŸ“š RAG (Retrieval-Augmented Generation)

- Past memory is retrieved when relevant
- Injected only into **system context**
- Prevents prompt leakage
- Reduces hallucinations
- Improves conversational continuity

---

## âš¡ Real-Time WebSocket UI

- Instant responses
- â€œğŸ¤– Thinkingâ€¦â€ indicator
- No page reloads
- Ready for token streaming upgrades

---

## ğŸ›  Tech Stack

| Layer | Technology |
|----|-----------|
Backend | FastAPI |
Real-time | WebSockets |
Agents | Microsoft AutoGen |
LLM | Ollama (Llama3) |
Language | Python 3.9+ |
Frontend | HTML + JavaScript |
Memory | JSON (extensible to FAISS) |

---

## ğŸ“‚ Project Structure
carebot-agent/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                    # Core agent orchestration
â”‚   â”œâ”€â”€ router.py                  # Intent classification & routing
â”‚   â”œâ”€â”€ rag.py                     # Retrieval-Augmented Generation
â”‚   â”œâ”€â”€ memory.py                  # Memory persistence layer
â”‚   â”œâ”€â”€ agent_care.py              # Empathetic CareBot agent
â”‚   â”œâ”€â”€ agent_memory_extractor.py  # Long-term memory extraction agent
â”‚   â”œâ”€â”€ safety.py                  # Safety & crisis handling logic
â”‚   â””â”€â”€ tools.py                   # Shared utilities
â”‚
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ server.py                  # FastAPI + WebSocket server
â”‚   â””â”€â”€ index.html                 # Minimal real-time UI
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ llm_config.py              # Ollama / LLM configuration
â”‚
â”œâ”€â”€ memory.json                    # Persistent long-term memory
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md


âš™ï¸ Installation & Setup

1ï¸âƒ£ Clone the Repository

git clone https://github.com/Ujjwal0207/carebot-agent.git
cd carebot-agent

2ï¸âƒ£ Create Virtual Environment

python3 -m venv .venv

source .venv/bin/activate     # macOS/Linux
.venv\Scripts\activate        # Windows

3ï¸âƒ£ Install Dependencies

pip install -r requirements.txt

ğŸ§  Install Ollama (Local LLM)

Download Ollama:
ğŸ‘‰ https://ollama.com

Pull a model:

ollama pull llama3


Keep Ollama running in the background.

âš™ï¸ LLM Configuration

config/llm_config.py

config_list = [
    {
        "model": "llama3",
        "base_url": "http://localhost:11434/v1",
        "api_key": "ollama"
    }
]

â–¶ï¸ Run the Application:

uvicorn web.server:app --reload


â–¶ï¸ Open in browser:

http://127.0.0.1:8000